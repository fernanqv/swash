{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# HySwash: A hybrid method for nearshore wave processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "* [1. Clustering and selection method MDA](#1.-Clustering-and-selection-method-MDA)\n",
    "\t* [1.1 Data preprocessing](#1.1-Data-preprocessing)\n",
    "\t* [1.2 MDA algorithm](#1.2-MDA-algorithm)<br><br>\n",
    "    \n",
    "* [2. Numerical model SWASH](#2.-Numerical-model-SWASH)\n",
    "\t* [2.1 Data preprocessing](#2.1-Data-preprocessing)   \n",
    "\t\t* [2.1.1 Cross-shore profile](#2.1.1-Cross-shore-profile)\n",
    "\t\t* [2.1.2 Friction](#2.1.2-Friction)     \n",
    "\t\t* [2.1.3 Vegetation](#2.1.3-Vegetation) \n",
    "\t* [2.2. Boundary conditions](#2.2-Boundary-conditions)\n",
    "\t\t* [2.2.1 Sea state](#2.2.1-Sea-state)\n",
    "\t\t* [2.2.2 Wind](#2.2.2-Wind)\n",
    "\t* [2.3. Run](#2.3-Run)\n",
    "\t* [2.4. Data Postprocessing](#2.4.-Data-Postprocessing)<br><br>\n",
    "    \n",
    "* [3. Time series reconstruction RBF](#3.-Time-series-reconstruction-RBF)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f1='/home/grupos/geocean/valvanuz/valvanuz_lustre/hySwash/hyswash/projects/test/0003/swash_input.pkl'\n",
    "with open(f1, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python libraries\n",
    "# basic\n",
    "import os\n",
    "import sys\n",
    "import os.path as op\n",
    "\n",
    "# common\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import HTML\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "\n",
    "# addpath to bluemath modules\n",
    "sys.path.insert(0, op.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# wrap_swash modules\n",
    "from wrap_swash.wswash.wrap import SwashProject, SwashWrap, SwashInput\n",
    "from wrap_swash.wswash.postprocessor import Postprocessor\n",
    "from wrap_swash.wswash.plots import SwashPlot\n",
    "from wrap_swash.wswash.io import SwashIO\n",
    "from wrap_swash.wswash.profiles import reef\n",
    "\n",
    "# statistical_toolkit  modules:\n",
    "from scipy.stats import qmc \n",
    "from statistical_toolkit.bluemathtk.MDA import *\n",
    "from statistical_toolkit.bluemathtk.PCA import *\n",
    "from hyswash.lib.output_extract import *\n",
    "from hyswash.lib.waves import series_TMA\n",
    "from hyswash.lib.reconstruction import RBF_Reconstruction_singular, RBF_Reconstruction_spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Initialization Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the project directory \n",
    "p_proj = op.abspath(op.join(os.getcwd(), '..', 'projects')) # swash projects main directory\n",
    "n_proj = 'test'                                             # project name\n",
    "\n",
    "\n",
    "p_data = op.join(p_proj, n_proj, 'data')\n",
    "print(p_data)\n",
    "if not os.path.exists(p_data):   os.makedirs(p_data)\n",
    "\n",
    "p_dataset = op.join(p_data, 'dataset.pkl')\n",
    "p_subset = op.join(p_data, 'subset.pkl')\n",
    "\n",
    "p_config = op.join(p_data, 'config')\n",
    "if not os.path.exists(p_config):   os.mkdir(p_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the project\n",
    "sp = SwashProject(p_proj, n_proj)\n",
    "sw = SwashWrap(sp)\n",
    "si = SwashIO(sp)\n",
    "sm = SwashPlot(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation period and grid resolution\n",
    "sp.tendc = 1800                          # simulation period (SEC)\n",
    "sp.warmup = 0.15 * sp.tendc              # spin-up time (s) (default 15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydraulic Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wind-sea states\n",
    "waves = xr.open_dataset('/home/grupos/geocean/valvanuz/valvanuz_lustre/hySwash/hyswash/data/demo/waves_csiro_demo.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "waves = waves.squeeze()\n",
    "df_dataset = pd.DataFrame(\n",
    "    {\n",
    "        'time': waves.time.values,\n",
    "        'hs': waves.hs.values, \n",
    "        'tp': waves.t.values, \n",
    "        'w': np.sqrt(waves.U10.values**2 + waves.V10.values**2),\n",
    "        'wdir': waves.dir.values,\n",
    "        'sl':waves.wl.values / 100\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Synthetic: Latine Sampling Hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of dimensions\n",
    "name_dims = ['Hs', 'Hs_L0', 'WL']\n",
    "\n",
    "# upper and lower bounds\n",
    "low_bounds = [0.5,    0.005,   0] \n",
    "upp_bounds =[   3,     0.05,   2] \n",
    "\n",
    "# number of samples to obtain\n",
    "n_dims = len(name_dims)\n",
    "n_samples = 10000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LHS execution\n",
    "sampler = qmc.LatinHypercube(d = n_dims, seed=1)\n",
    "dataset = sampler.random(n = n_samples)\n",
    "dataset = qmc.scale(dataset, low_bounds, upp_bounds)\n",
    "\n",
    "# convert to dataframe\n",
    "df_dataset = pd.DataFrame(data=dataset, columns=name_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ['Hs', 'Hs_L0', 'WL']\n",
    "\n",
    "fig = scatter_mda([df_dataset[dims]], names = dims, figsize=(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering & Selection Method MDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high computational cost of propagating the entire hindcast dataset requires statistical tools to reduce the set of data to a number of representative cases to perform hybrid downscaling. The maximum dissimilarity algorithm (MDA) defined in the work of Camus et al., 2011, is implemented for this purpose.<br>\n",
    "    <br>\n",
    "Given a data sample $X=\\{x_{1},x_{2},…,x_{N}\\}$ consisting of $N$ $n$-dimensional vectors, a subset of $M$ vectors $\\{v_{1},…,v_{M}\\}$ representing the diversity of the data is obtained by applying this algorithm. The selection starts initializing the subset by transferring one vector from the data sample ${v1}$. The rest of the $M-1$ elements are selected iteratively, calculating the dissimilarity between each remaining data in the database and the elements of the subset and transferring the most dissimilar one to the subset. The process finishes when the algorithm reaches $M$ iterations.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset, scalar and directional indexes\n",
    "ix_scalar = [0, 1, 2]      \n",
    "ix_directional = []        \n",
    "n_subset = 5\n",
    "\n",
    "# MDA algorithm\n",
    "out = MaxDiss_Simplified_NoThreshold(\n",
    "    df_dataset[name_dims].values, \n",
    "    n_subset, \n",
    "    ix_scalar, ix_directional\n",
    ")\n",
    "\n",
    "df_subset = pd.DataFrame(data=out, columns=name_dims)\n",
    "df_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot subset-dataset\n",
    "dims = ['Hs', 'Hs_L0', 'WL']\n",
    "fig = scatter_mda([df_dataset[dims], df_subset[dims]], names =dims, figsize=(7,7), ss=[10, 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical model SWASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, the computational grid is defined from the bathymetric data and, optionally, wave dissipation characteristics due to the bottom friction or vegetation. The input grids will be considered uniform and rectangular, with the computational grid covering the whole bathymetric region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-shore profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model boundaries should be far enough from the area of interest and away from steep topography to avoid unrealistic frictional or numerical dispersion effects but close enough to remain computationally feasible kh < 5. As a recommendation, the area of interest should be kept at least two wave lengths away from the boundary. In the following cells, different input choices for defining the cross-shore profile will be given. \n",
    " \n",
    "* `dxL`  : number of nodes per wavelength. This command sets the grid resolution from the number of nodes desired per wavelength in 1m depth (assuming that in the beach due to the infragravigity waves the water colum can reach 1m heigh). \n",
    "\n",
    "* `dxinp`: The resolution of the bathymetric grid is not the same as that of the computational grid. It is advised to avoid extremely steep bottom slopes or sharp obstacles as much as posible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Land points are defined as negative while wet points are defined as positive.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bathymetry from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import depth FILE\n",
    "sp.dxL = 30                                                     # nº nodes per wavelength\n",
    "sp.dxinp = 1                                                    # bathymetry spacing resolution (m)\n",
    "\n",
    "depth = np.loadtxt('/home/grupos/geocean/valvanuz/valvanuz_lustre/hySwash/hyswash/data/demo/depth.bot' )        # depth file path\n",
    "sp.depth = depth \n",
    "\n",
    "fig = sm.plot_depthfile() \n",
    "\n",
    "fig.savefig(op.join(p_config, 'coral_reef_profile.png'), dpi=600)\n",
    "np.savetxt(op.join(p_config, 'depth.txt'), depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coral-reef Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.b_grid.dx = 1            # bathymetry mesh resolution at x axes (m)\n",
    "sp.dxL = 40                 # nº nodes per wavelength\n",
    "sp.dxinp = 1                # bathymetry spacing resolution (m\n",
    "sp.dyinp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = 15                     # offshore depth (m)\n",
    "Slope1 = 0.05               # fore shore slope\n",
    "Slope2 = 0.1                # inner shore slope\n",
    "Wreef = 200                 # reef bed width (m)\n",
    "Wfore = 500                 # flume length before fore toe (m)\n",
    "bCrest = 10                 # beach heigh (m)\n",
    "emsl = 2.5                  # mean sea level (m)\n",
    "\n",
    "depth = reef(sp.b_grid.dx, h0, Slope1, Slope2, Wreef, Wfore, bCrest, emsl)\n",
    "\n",
    "sp.set_depth(depth, sp.dxinp, sp.dyinp)\n",
    "\n",
    "fig = sm.plot_depthfile()\n",
    "\n",
    "fig.savefig(op.join(p_config, 'coral_reef_profile.png'), dpi=600)\n",
    "np.savetxt(op.join(p_config, 'depth.txt'), depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With this option the user can activate the bottom friction controlled by the Manning formula. As the friction coefficient may vary over the computational region, the friction data can be read from file or defined by specifyng the start and end point along it is defined the frictional area (e.g. reef). \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a constant friction between two points of the profile \n",
    "sp.friction_file = False\n",
    "sp.friction = True\n",
    "sp.Cf = 0.01                       # manning frictional coefficient  (m^-1/3 s)\n",
    "sp.cf_ini = 0                      # first point along the profile \n",
    "sp.cf_fin = 800                    # last point along the profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary conditions\n",
    "\n",
    "The boundaries of the computational grid in SWASH are either land, beach or water. The wave condition is imposed on the west boundary of the computational domain, so that the wave propagation is pointing eastward. To simulate entering waves without some reflections at the wavemaker boundary, a weakly-reflective boundary condition allowing outgoing waves is adopted. For this test case, a time series synthesized from parametric information (wave height, period, etc.) will be given as wavemaker. Here, the wavemaker must be defined as irregular unidirectional waves by means of 1D spectrum. Both the initial water level and velocity components are set to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sea state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wave series and save 'waves.bnd' file\n",
    "sp.deltat = 1              # delta time over which the wave series is defined\n",
    "\n",
    "sp.non_hydrostatic = True  # True or False\n",
    "sp.vert = 1                # vertical layers\n",
    "sp.delttbl = 1             # time between output fields (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['H'] = df_subset['Hs']\n",
    "df_subset['T'] = np.sqrt((df_subset['Hs'].values * 2 * np.pi) / (9.806 * df_subset['Hs_L0']))\n",
    "df_subset['gamma'] = 2\n",
    "df_subset['warmup'] = sp.warmup\n",
    "df_subset['deltat'] = sp.deltat\n",
    "df_subset['tendc'] = sp.tendc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input waves definition at `waves.py`: <br>\n",
    "series_regular_monochromatic, series_regular_bichromatic <br>\n",
    "series_Jonswap, series_TMA <br>\n",
    "series_Jonswap_bimiodal, series_TMA_bimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of swash wrappers\n",
    "list_wrap = []\n",
    "for iw, waves in df_subset.iterrows():\n",
    "    \n",
    "    sys.stdout.write('\\rCase {0}'.format(iw))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    series = series_TMA(waves, depth[0])\n",
    "    \n",
    "    si = SwashInput() \n",
    "    si.waves_parameters = waves\n",
    "    si.waves_series = series\n",
    "    \n",
    "    list_wrap.append(si)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SwashWrap(sp)\n",
    "waves = sw.build_cases(list_wrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can optionally specify wind speed, direction and wind drag assuming constant values in the domain. As the test case is using cartesian coordinates, please set the direction where the wind cames from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define wind parameters\n",
    "sp.wind = False           # wind direction at 10 m height (º)\n",
    "sp.Ca = 0.0026           # dimensionless coefficient (default 0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following, a series of predefined options have been choosen: <br></span>\n",
    "\n",
    "* Grid resolution is determined through a number of points per wavelength criteria: Courant number for numerical stability, number of points per wavelength, and manual upper and lower limits for grid cell sizes\n",
    "\n",
    "* The default value for the maximun wave breaking steepness parameter is $ \\alpha = 0.6$\n",
    "\n",
    "* For high, nonlinear waves, or wave interaction with structures with steep slopes (e.g. jetties, quays), a Courant number of 0.5 is advised. Here, a dynamically adjusted time step controlled by a Courant number range of (0.1 - 0.5) is implemented\n",
    "\n",
    "User parametes:\n",
    "\n",
    "* `Nonhydrostatic` : to include the non-hydrostatic pressure in the shallow water equations. Hydrostatic pressure assumption can be made in case of propagation of long waves, such as large-scale ocean circulations, tides and storm surges. This assumption does not hold in case of propagation of short waves, flows over a steep bottom, unstable stratified flows, and other small-scale applications where vertical acceleration is dominant \n",
    "* `vert` : this command set the number of vertical layers in case that the run will be in multi-layered mode \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cases\n",
    "sw.run_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different output quantities will be given here to go over the different wave transformation processes including wave propagation, dispersion, flooding and drying, moving shoreline, surf-beat, infragravity waves, set-up induced by wave breaking, run-up and overtopping discharge. \n",
    "\n",
    "To this end, the time-dependent surface elevation is stored at every grid point for every time step. After removing the warmup time from the sea surface series, a FFt is applied to obtain its representation in the frequency domain. A further classification is given by spliting the wave frequency into incident waves IC (0.04 - 1), infragravity waves IG (0.004 - 0.04) and very low frequency VLF (0.001 - 0.004). \n",
    "\n",
    "The run-up heigh is computed by the intersection between free surface and bottom level considering a minimun  depth of 1cm after each time step. \n",
    "\n",
    "The mean wave overtopping discharge q (ms/l) is outputted at the highest elevation point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert raw SWASH output to netcdf files\n",
    "sw.output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables to compute\n",
    "output_vars = ['Ru2', 'Msetup', 'RuDist', 'Hrms', 'Hfreqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'run_post' to True to run postprocessing of each case\n",
    "sdp = Postprocessor(sp, si, sw, output_vars, run_post=False)\n",
    "sdp.ds_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sea Surface Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 4\n",
    "ani = sm.animate_case_propagation(sp, case, tini=100, tend=200, tstep=4, figsize=(15,5))\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction - Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The reconstruction of the time series of wave parameters in the position of the buoy is carried out by an interpolation technique based on radial basis functions (RBF), a scheme wich is very convenient for scatter and multivariate data. The RBF approximation has been applied successfully in many fields, usually with better results than other interpolation methods (Hardy, 1990).\n",
    "    \n",
    "Suppose that $f=f(x)$ is the real-valued function that we want to approximate. We are given M scattered data points $\\{x_1,..., x_M\\}$ of dimension $\\textit{n}$ and the associated real function values $\\{f_1, ..., f_M\\}$, being $f_i = f(x_j), j = 1,...,M$. The RBF interpolation method consists of a weighted sum of radially symmetric basic functions located at the data points. The approximation function is assumed to be of the form:\n",
    "\n",
    "$RBF(x) = p(x) + \\sum\\limits_{j=1}^M a_j\\Phi{\\large (}{\\large \\parallel}{x - x_j}{\\large \\parallel}{\\large )}$&nbsp;&nbsp;&nbsp;&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['Ru2']\n",
    "\n",
    "ix_scalar_subset = [0, 1, 2]\n",
    "ix_scalar_target = [0]\n",
    "ix_directional_subset = []\n",
    "ix_directional_target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF reconstruction\n",
    "df_output = RBF_Reconstruction_singular(\n",
    "    sdp, var, dims, df_dataset, df_subset,\n",
    "    ix_scalar_subset, ix_directional_subset, \n",
    "    ix_scalar_target, ix_directional_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = scatter_color(df_dataset, df_output, dims, var, figsize=(7,7), vmin=None, vmax=None, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['Msetup']                 # variable to reconstruct\n",
    "X_max = 1000                     # maximum spatial X to consider for PCA\n",
    "variance = 99.8                  # maximum variance to explain\n",
    "\n",
    "ix_scalar_subset = [0, 1, 2]    \n",
    "ix_scalar_target = [0]\n",
    "ix_directional_subset = []\n",
    "ix_directional_target = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA and apply RBF recosntruction\n",
    "xds_PCA, ds_output = RBF_Reconstruction_spatial(\n",
    "    sdp, var, dims, df_dataset, df_subset,\n",
    "    ix_scalar_subset, ix_directional_subset, \n",
    "    ix_scalar_target, ix_directional_target, variance, X_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot PCA results: EOFs + PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA(xds_PCA, df_subset, dims, figsize1=(6+1,6), figsize2=(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pablov1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
